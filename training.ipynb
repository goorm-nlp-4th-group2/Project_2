{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2supfKwTYazF"},"outputs":[],"source":["!set -x \\\n","&& pip install konlpy \\\n","&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x\n","!pip install git+https://github.com/ssut/py-hanspell\n","!pip install transformers datasets wandb sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNhw3-jJYtYx"},"outputs":[],"source":["import os\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","os.chdir(\"/content/drive/MyDrive/NLP_Project_2\")\n","\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","\n","fine_tuned_model_name = \"write_your_model_name\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUn0feip5pGy"},"outputs":[],"source":["!wandb login\n","\n","import wandb\n","wandb.init(project = \"Goorm_2nd_project\", entity = \"2nd_group\", name = fine_tuned_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKNqtQPVYeZv"},"outputs":[],"source":["import pandas as pd\n","import json\n","import torch\n","import datasets\n","import numpy as np\n","import random\n","import nltk\n","import re\n","import torch.nn.functional as F\n","import utils\n","import seaborn as sns\n","\n","from glob import glob\n","from konlpy.tag import Mecab\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoTokenizer, DataCollatorWithPadding, get_cosine_schedule_with_warmup\n","from transformers import AutoModelForQuestionAnswering\n","from collections import defaultdict, deque\n","from tqdm import tqdm\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","SEED = 20220803\n","BACKBONE = \"kykim/bert-kor-base\"\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if \"cuda\" in device.type :\n","    torch.cuda.set_device(device)\n","print(device)\n","\n","tokenizer = AutoTokenizer.from_pretrained(BACKBONE, do_lower_case = False)\n","tagger = Mecab()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oisitb_NDLo"},"outputs":[],"source":["original_train = utils.load_data(\"./RawData/train.json\", do_preprocessing = True)\n","\n","temp = []\n","for uid in tqdm(original_train.guid.unique()) :\n","    candidate = original_train.loc[original_train.guid == uid, :]\n","    candidate = candidate.sort_values(\"answer\", key = lambda x : x.str.len(), ascending = False)\n","    temp.append(candidate.reset_index(drop = True).loc[0, :])\n","original_train = pd.DataFrame(temp).reset_index(drop = True)\n","\n","original_train.loc[:, \"source\"] = \"kaggle\"\n","original_train = original_train.drop(\"guid\", axis = \"columns\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O386BuQ5ZDAa"},"outputs":[],"source":["batch_size = 16\n","collator = DataCollatorWithPadding(tokenizer, return_tensors = \"pt\")\n","\n","train_pd, valid_pd = train_test_split(original_train, random_state = SEED, test_size = .3)\n","\n","train_data = utils.get_dataset(train_pd.reset_index(drop = True), tokenizer, collator, batch_size, True)\n","valid_data = utils.get_dataset(valid_pd.reset_index(drop = True), tokenizer, collator, batch_size * 2, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRMub51qJcAO"},"outputs":[],"source":["learning_rate = 1e-5\n","epochs = 3\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(BACKBONE)\n","model.train()\n","model = model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, eps = 1e-6, weight_decay = 0.02)\n","\n","lr_scheduler = get_cosine_schedule_with_warmup(optimizer = optimizer,\n","                                               num_warmup_steps = int(len(train_data) * epochs * 0.06),\n","                                               num_training_steps = len(train_data) * epochs)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1660982152419,"user":{"displayName":"박정민","userId":"11203274198292799302"},"user_tz":-540},"id":"mXQgBZaVNQnm"},"outputs":[],"source":["wandb_config = {\n","    \"learning_rate\" : learning_rate,\n","    \"batch_size\" : batch_size,\n","    \"backbone\" : BACKBONE,\n","    \"epochs\" : epochs\n","}\n","\n","wandb.config.update(wandb_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRF-XdDcg1Ne"},"outputs":[],"source":["scaler = torch.cuda.amp.GradScaler()\n","\n","wandb.watch(model, log = \"all\", log_freq = 10)\n","\n","for epoch in range(epochs) :\n","    cum_loss = deque(maxlen = 20)\n","    cum_dist = deque(maxlen = 20)\n","    cum_start_acc = deque(maxlen = 20)\n","    cum_end_acc = deque(maxlen = 20)\n","\n","    curr_loss = []\n","    curr_dist = []\n","    curr_start_acc = []\n","    curr_end_acc = []\n","\n","    with tqdm(train_data, unit = \" batch\") as tepoch :\n","        curr_loss.clear()\n","        model.train()\n","        for i, batch in enumerate(tepoch) :\n","            optimizer.zero_grad()\n","            tepoch.set_description(f\"Train Epoch {epoch}\")\n","\n","            g_answer = batch[\"golden_answer\"]\n","            batch = {k : v.to(device) for k, v in batch.items() if k != \"golden_answer\"}            \n","\n","            with torch.cuda.amp.autocast() :\n","                outputs = model(**batch)\n","                start_logits = outputs[\"start_logits\"]\n","                end_logits = outputs[\"end_logits\"]\n","                loss = utils.weighted_loss_fn(start_logits, end_logits, batch[\"start_positions\"], batch[\"end_positions\"], .3, .7)\n","            \n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            lr_scheduler.step()\n","\n","            cum_loss.append(float(loss))\n","            curr_loss.append(float(loss))\n","\n","            start_acc, end_acc = utils.extract_accuracy(start_logits, end_logits, batch[\"start_positions\"], batch[\"end_positions\"])\n","            cum_start_acc.append(float(start_acc))\n","            cum_end_acc.append(float(end_acc))\n","            curr_start_acc.append(float(start_acc))\n","            curr_end_acc.append(float(end_acc))\n","\n","            dist = utils.levenshtein_distance(start_logits, end_logits, g_answer, batch[\"input_ids\"], tokenizer, tagger, threshold = 0)\n","            cum_dist.append(float(dist))\n","            curr_dist.append(float(dist))\n","\n","            tepoch.set_postfix(loss = sum(cum_loss) / len(cum_loss),\n","                               dist = sum(cum_dist) / len(cum_dist),\n","                               start_acc = sum(cum_start_acc) / len(cum_start_acc),\n","                               end_acc = sum(cum_end_acc) / len(cum_end_acc))\n","            \n","            wandb.log({\"train_loss\" : sum(cum_loss) / len(cum_loss),\n","                       \"train_dist\" : sum(cum_dist) / len(cum_dist),\n","                       \"train_start_acc\" : sum(cum_start_acc) / len(cum_start_acc),\n","                       \"train_end_acc\" : sum(cum_end_acc) / len(cum_end_acc),\n","                       \"lr\" : optimizer.state_dict()[\"param_groups\"][0]['lr'],\n","                       \"train_step\" : i + (len(train_data) * epoch)})\n","            \n","        print(\"Train loss : \", sum(curr_loss) / len(curr_loss))\n","        print(\"Train dist : \", sum(curr_dist) / len(curr_dist))\n","        print(\"Train start acc :\", sum(curr_start_acc) / len(curr_start_acc))\n","        print(\"Train end acc :\", sum(curr_end_acc) / len(curr_end_acc))\n","\n","    curr_loss.clear()\n","    curr_dist.clear()\n","    curr_start_acc.clear()\n","    curr_end_acc.clear()\n","\n","    cum_loss.clear()\n","    cum_dist.clear()\n","    cum_start_acc.clear()\n","    cum_end_acc.clear()\n","    \n","    with tqdm(valid_data, unit = \" batch\") as tepoch :\n","        model.eval()\n","        with torch.no_grad() :\n","            for i, batch in enumerate(tepoch) :\n","                tepoch.set_description(f\"Valid Epoch {epoch}\")\n","\n","                g_answer = batch[\"golden_answer\"]\n","                batch = {k : v.to(device) for k, v in batch.items() if k != \"golden_answer\"}            \n","\n","                with torch.cuda.amp.autocast() :\n","                    outputs = model(**batch)\n","                    start_logits = outputs[\"start_logits\"]\n","                    end_logits = outputs[\"end_logits\"]\n","                    loss = utils.weighted_loss_fn(start_logits, end_logits, batch[\"start_positions\"], batch[\"end_positions\"], .3, .7)\n","\n","                cum_loss.append(float(loss))\n","                curr_loss.append(float(loss))\n","\n","                start_acc, end_acc = utils.extract_accuracy(start_logits, end_logits, batch[\"start_positions\"], batch[\"end_positions\"])\n","                cum_start_acc.append(float(start_acc))\n","                cum_end_acc.append(float(end_acc))\n","                curr_start_acc.append(float(start_acc))\n","                curr_end_acc.append(float(end_acc))\n","\n","                dist = utils.levenshtein_distance(start_logits, end_logits, g_answer, batch[\"input_ids\"], tokenizer, tagger, threshold = 0)\n","                cum_dist.append(float(dist))\n","                curr_dist.append(float(dist))\n","\n","                tepoch.set_postfix(loss = sum(cum_loss) / len(cum_loss),\n","                                dist = sum(cum_dist) / len(cum_dist),\n","                               start_acc = sum(cum_start_acc) / len(cum_start_acc),\n","                               end_acc = sum(cum_end_acc) / len(cum_end_acc))\n","                \n","    wandb.log({\"valid_loss\" : sum(curr_loss) / len(curr_loss),\n","                \"valid_dist\" : sum(curr_dist) / len(curr_dist),\n","                \"valid_start_acc\" : sum(curr_start_acc) / len(curr_start_acc),\n","                \"valid_end_acc\" : sum(curr_end_acc) / len(curr_end_acc),\n","                \"valid_step\" : epoch + 1})\n","\n","    print(\"Valid loss : \", sum(curr_loss) / len(curr_loss))\n","    print(\"Valid dist : \", sum(curr_dist) / len(curr_dist))\n","    print(\"Valid start acc :\", sum(curr_start_acc) / len(curr_start_acc))\n","    print(\"Valid end acc :\", sum(curr_end_acc) / len(curr_end_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGQCKEkpfVYm"},"outputs":[],"source":["model.save_pretrained(\"./Model/\" + fine_tuned_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeIXyTCtiohJ"},"outputs":[],"source":["def get_scores_in_dataset(model, input_data, tokenizer, tagger, golden_answer = False) :\n","    inferenced = []\n","    scores = []\n","    answers = []\n","\n","    with tqdm(input_data, unit = \" batch\") as tepoch :\n","        model.eval()\n","        with torch.no_grad() :\n","            for i, batch in enumerate(tepoch) :\n","                tepoch.set_description(f\"Score\")\n","                if golden_answer :\n","                    g_answer = batch[\"golden_answer\"]\n","                batch = {k : v.to(device) for k, v in batch.items() if k != \"golden_answer\"}            \n","\n","                with torch.cuda.amp.autocast() :\n","                    outputs = model(**batch)\n","                    start_logits = outputs[\"start_logits\"]\n","                    end_logits = outputs[\"end_logits\"]\n","                \n","                for idx, v in enumerate(batch[\"input_ids\"]) :\n","                    infer, score = utils.inference(start_logits[idx], end_logits[idx], v, 20, tokenizer, tagger)\n","                    inferenced.append(infer)\n","                    scores.append(score)\n","                    if golden_answer :\n","                        answers.append(tokenizer.decode(g_answer[idx], skip_special_tokens = True))\n","    return inferenced, scores, answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94lqAEEbNCgF"},"outputs":[],"source":["train_inferenced, train_scores, train_answers = get_scores_in_dataset(model, train_data, tokenizer, tagger, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUHukWoqNDKQ"},"outputs":[],"source":["compare = pd.DataFrame({\"original_inference\" : train_inferenced,\n","                        \"answer\" : train_answers})\n","\n","compare.loc[:, \"cleaned_inference\"] = compare.original_inference.apply(lambda x : utils.remove_postposition(x))\n","\n","before = []\n","after = []\n","for i in range(len(compare)) :\n","    before.append(nltk.edit_distance(compare.loc[i, \"original_inference\"], compare.loc[i,\"answer\"]))\n","    after.append(nltk.edit_distance(compare.loc[i,\"cleaned_inference\"], compare.loc[i, \"answer\"]))\n","print(\"수정 전 평균 편집거리 :\", sum(before) / len(before))\n","print(\"수정 후 평균 편집거리 :\", sum(after) / len(after))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfsm57zIqMNa"},"outputs":[],"source":["valid_inferenced, valid_scores, valid_answers = get_scores_in_dataset(model, valid_data, tokenizer, tagger, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6rVQkCY6_ez"},"outputs":[],"source":["sns.distplot(torch.tensor(valid_scores))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIIkXBl8Lkcx"},"outputs":[],"source":["submission = pd.read_csv(\"./RawData/baseline.csv\")\n","submission.loc[:, \"Predicted\"] = inferenced\n","submission.to_csv(\"./Submission/Submission_4.csv\", index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"training.ipynb","provenance":[],"authorship_tag":"ABX9TyPHMu7xHWrj3O/N/muJMuO3"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}